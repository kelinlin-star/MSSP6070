{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOQuQMoM1jJ4JcSFxHddnjN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kelinlin-star/MSSP6070/blob/main/Assignments/Participation_Activity_9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import time\n",
        "\n",
        "# Function to download images from a given Imgur search URL\n",
        "def download_images(search_query, num_images=10):\n",
        "    # Create a directory to store images\n",
        "    if not os.path.exists(search_query):\n",
        "        os.makedirs(search_query)\n",
        "\n",
        "    # Create the search URL on Imgur\n",
        "    url = f\"https://imgur.com/search?q={search_query}\"\n",
        "\n",
        "    # Custom headers to mimic a browser request\n",
        "    headers = {\n",
        "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
        "    }\n",
        "\n",
        "    # Send an HTTP request to get the content of the page\n",
        "    response = requests.get(url, headers=headers)\n",
        "    if response.status_code != 200:\n",
        "        print(f\"Failed to retrieve the page: {response.status_code}\")\n",
        "        return\n",
        "\n",
        "    # Parse the HTML content\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    # Find all image tags in the page, which could be lazy-loaded\n",
        "    img_tags = soup.find_all('img')\n",
        "\n",
        "    # Limit the number of images to download (to prevent downloading too many)\n",
        "    img_count = 0\n",
        "\n",
        "    for img_tag in img_tags:\n",
        "        # Get the image URL from the 'src' or 'data-src' attribute (for lazy-loaded images)\n",
        "        img_url = img_tag.get('src') or img_tag.get('data-src')\n",
        "\n",
        "        # Only consider images with a valid URL\n",
        "        if img_url and img_url.startswith('https://'):\n",
        "            # Get the file name from the image URL\n",
        "            img_name = os.path.join(search_query, img_url.split('/')[-1])\n",
        "\n",
        "            # Download the image\n",
        "            try:\n",
        "                img_data = requests.get(img_url).content\n",
        "                with open(img_name, 'wb') as f:\n",
        "                    f.write(img_data)\n",
        "                    print(f\"Downloaded {img_name}\")\n",
        "                    img_count += 1\n",
        "                if img_count >= num_images:  # Stop after downloading the specified number of images\n",
        "                    break\n",
        "            except Exception as e:\n",
        "                print(f\"Failed to download {img_url}: {e}\")\n",
        "\n",
        "            # Wait a few seconds before making another request to avoid rate limiting\n",
        "            time.sleep(2)  # Sleep for 2 seconds\n",
        "\n",
        "# Main entry point\n",
        "if __name__ == '__main__':\n",
        "    search_query = input(\"Enter the category of images you want to download (e.g., cats, nature): \")\n",
        "    num_images = int(input(\"How many images would you like to download? \"))\n",
        "    download_images(search_query, num_images)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oTm16comQAUd",
        "outputId": "aa916c80-0045-4ad3-f434-964941249737"
      },
      "execution_count": 4,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter the category of images you want to download (e.g., cats, nature): cats\n",
            "How many images would you like to download? 2\n"
          ]
        }
      ]
    }
  ]
}